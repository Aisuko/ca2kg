{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12901053,"sourceType":"datasetVersion","datasetId":8162483},{"sourceId":12936708,"sourceType":"datasetVersion","datasetId":8185966},{"sourceId":250973825,"sourceType":"kernelVersion"},{"sourceId":259916067,"sourceType":"kernelVersion"},{"sourceId":260589889,"sourceType":"kernelVersion"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom doraemon import Doraemon\nfrom kg_rag import Inference, KG_RAG_Tool, PromptBuilder\n\n\nclass IoE:\n    PROMPT = {\n        \"ioe\": (\n            \"If you are very confident about your answer, maintain your answer. \"\n            \"Otherwise, update your answer. The final answer MUST be returned in this exact format at the very end: \"\n            \"\\\\boxed{{final answer}}\\n\"\n            # Output-only constraint:\n            \"Your entire response MUST be exactly that single boxed answer. \"\n            \"Do not include any other text, punctuation, quotes, code fences, or reasoning.\"\n        ),\n        'fact_kg':{\n            \"gen\": (\n                \"Provide your single best guess for the following fact checking question. \"\n                \"Give ONLY the guess, no other words or explanation.\\n\\n\"\n                \"Return ONLY the guess in this EXACT format:\\n\"\n                \"\\\\boxed{guess}\\n\"\n            )\n        },\n    }\n\n    # -------- helpers --------\n    @staticmethod\n    def _format_contexts(ctxs) -> str:\n        \"\"\"\n        Turn contexts (None | str | List[str]) into numbered lines:\n        Context1: ...\n        Context2: ...\n        \"\"\"\n        if ctxs is None:\n            return \"\"\n        if not isinstance(ctxs, (list, tuple)):\n            ctxs = [ctxs]\n        lines = []\n        for i, c in enumerate(ctxs, 1):\n            if c is None:\n                continue\n            s = str(c).strip()\n            if s:\n                lines.append(f\"Context{i}: {s}\")\n        return \"\\n\".join(lines)\n\n    # -------- user content builder --------\n    @classmethod\n    def build_user(cls, question, contexts, previous_answer) -> str:\n        q = (question or \"\").strip()\n        ctx_block = cls._format_contexts(contexts)\n        prev = (previous_answer or \"\").strip()\n\n        parts = [f\"Question: {q}\"]\n        if ctx_block:\n            parts.append(ctx_block)\n        parts.append(f\"Previous Answer: {prev}\")\n        return \"\\n\".join(parts)\n\n    # -------- message pack builders (system + user) --------\n    @classmethod\n    def msgs_ioe(cls, question, contexts, previous_answer):\n        \"\"\"\n        Returns a list[dict] with roles 'system' and 'user'.\n        \"\"\"\n        return [\n            {\"role\": \"system\", \"content\": cls.PROMPT[\"ioe\"]},\n            {\"role\": \"user\", \"content\": cls.build_user(question, contexts, previous_answer)},\n        ]\n\n    @classmethod\n    def msgs_ioe_from_row(cls, row):\n        \"\"\"\n        Convenience: build from a pandas Series/dict-like row with:\n          - 'question'   : str\n          - 'ctx_topk'   : List[str] or str\n          - 's_out'      : str (previous answer)\n        \"\"\"\n        return cls.msgs_ioe(\n            question=row.get(\"question\", \"\"),\n            contexts=row.get(\"ctx_topk\", []),\n            previous_answer=row.get(\"s_out\", \"\")\n        )\n\ndef classify(x: str, n: int = 1200, dataset: str = \"metaqa\") -> pd.DataFrame:\n    BASE_PATHS = {\n        \"metaqa\": \"/kaggle/input/filtered-multiple-hops-metaqa\",\n        \"webqsp\": \"/kaggle/input/webqsp\"\n    }\n\n    # Validate dataset input\n    if dataset not in BASE_PATHS:\n        raise ValueError(f\"Invalid dataset '{dataset}'. Must be one of: {list(BASE_PATHS.keys())}\")\n\n    base = BASE_PATHS[dataset]\n    x = (x or \"\").strip().lower()\n\n    # Select file path based on dataset type\n    if dataset == \"metaqa\":\n        match x:\n            case \"one\":\n                path = f\"{base}/one_hop_supported.pickle\"\n            case \"three\" | _:\n                path = f\"{base}/three_hop_supported.pickle\"\n    else:  # dataset == \"another\"\n        match x:\n            case \"one\":\n                path = f\"{base}/webqsp_ctxstyle_1200_hop1_nl.pkl\"\n            case \"three\":\n                path = f\"{base}/webqsp_ctxstyle_1200_hop3_nl.pkl\"\n            case \"two\" | _:\n                raise ValueError(\"‚ùå 'two_hop_supported.pickle' does not exist in the 'current' dataset.\")\n\n    # Load and return dataframe\n    df = pd.read_pickle(path)\n\n    if dataset ==\"webqsp\":\n        df=df.rename(columns={\n            \"ground_truth\":\"Label\",\n            \"contexts\": \"ctx_topk\"\n        })\n    \n    return df.head(n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset=\"webqsp\"\n\ndf = classify(\"three\", n = 1200, dataset=dataset)\n\n\ndf['query'] = df.apply(lambda row: [\n    {\"role\": \"system\", \"content\": IoE.PROMPT['fact_kg']['gen']},\n    {\"role\": \"user\", \"content\": PromptBuilder.build_user_multi_contents(row['question'], row['ctx_topk'])}\n], axis=1)\n\nDoraemon.set_provider('llama3')\nlogger = Doraemon.get_logger(logfile='if_or_else.log')\ntasks = df.to_dict(orient='records')\nstandard_out = await Inference.process_batches(tasks, logger, 'query')\ndf['s_out'] = pd.Series(standard_out, dtype='object')\ndf['s_out'] = df['s_out'].apply(KG_RAG_Tool.extract_boxed_answer)\n\ndf['ioe_prompt'] = df.apply(IoE.msgs_ioe_from_row, axis=1)\n\ntasks = df.to_dict(orient='records')\nioe_a = await Inference.process_batches(tasks, logger, 'ioe_prompt')\ndf['ioe_a'] = pd.Series(ioe_a, dtype='object')\n\ndf['ioe_a'] = df['ioe_a'].apply(KG_RAG_Tool.extract_boxed_answer)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stats = KG_RAG_Tool.eval_accuracy(df, pred=\"ioe_a\", g_t=\"Label\")\nprint(f\"Accuracy: {stats['accuracy']:.2%}  ({stats['num_correct']} / {stats['total']})\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false},"outputs":[],"execution_count":null}]}