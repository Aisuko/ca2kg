{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12901053,"sourceType":"datasetVersion","datasetId":8162483},{"sourceId":12936708,"sourceType":"datasetVersion","datasetId":8185966},{"sourceId":250973825,"sourceType":"kernelVersion"},{"sourceId":259916067,"sourceType":"kernelVersion"},{"sourceId":260589889,"sourceType":"kernelVersion"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom kg_rag import Inference, KG_RAG_Tool\nfrom doraemon import Doraemon\n\n# --- Self-correct prompt builder (3 steps: solve → review → revise) ---\nfrom typing import List, Optional, Sequence\n\nclass SelfCorrectPromptBuilder:\n    PROMPT = {\n        \"solve\": (\n            \"## Role & Objective\\n\"\n            \"You are answering a question using ONLY the provided contexts.\\n\"\n            \"Requirements:\\n\"\n            \"- Use information strictly from the contexts; do not rely on outside knowledge.\\n\"\n            \"- Show concise, step-by-step reasoning.\\n\"\n            \"- The final answer MUST be a short phrase or a single number, returned in this exact format at the very end:\\n\"\n            \"  \\\\boxed{{answer}}\\n\"\n            \"\\n\"\n            \"## Provided Contexts\\n\"\n            \"{context}\\n\"\n            \"\\n\"\n            \"## Question\\n\"\n            \"{question}\\n\"\n        ),\n        \"review\": (\n            \"## Task: Review the previous solution for the question (do NOT provide a new solution)\\n\"\n            \"Review the answer using ONLY the provided contexts and identify issues. Focus on:\\n\"\n            \"- Misuse or omission of relevant context.\\n\"\n            \"- Logical/arithmetical mistakes.\\n\"\n            \"- Whether the final answer matches the facts in context.\\n\"\n            \"- Whether the output format (final answer in \\\\boxed{{answer}}) was followed.\\n\"\n            \"- If contexts are insufficient, the answer should be exactly 'Insufficient information'.\\n\"\n            \"\\n\"\n            \"## Provided Contexts\\n\"\n            \"{context}\\n\"\n            \"\\n\"\n            \"## Question\\n\"\n            \"{question}\\n\"\n            \"\\n\"\n            \"## Previous Solution\\n\"\n            \"{previous_answer}\\n\"\n            \"\\n\"\n            \"Explicitly remind that the final corrected answer in the next step must be returned in this format: \"\n            \"\\\\boxed{{answer}}.\"\n        ),\n        \"revise\": (\n            \"## Task: Revise the previous solution\\n\"\n            \"Using ONLY the provided contexts, fix the reasoning and provide the best final answer for the  question.\\n\"\n            \"Requirements:\\n\"\n            \"- Correct any misinterpretations and errors noted in the review.\\n\"\n            \"- If contexts are insufficient, reply exactly with 'Insufficient information'.\\n\"\n            \"- Keep reasoning concise and accurate.\\n\"\n            \"- The final answer MUST be a short phrase or a single number, returned in this exact format at the very end:\\n\"\n            \"  \\\\boxed{{answer}}\\n\"\n            \"- Do NOT add any text after the boxed answer.\\n\"\n            \"\\n\"\n            \"## Provided Contexts\\n\"\n            \"{context}\\n\"\n            \"\\n\"\n            \"## Question\\n\"\n            \"{question}\\n\"\n            \"\\n\"\n            \"## Your Earlier Solution\\n\"\n            \"{previous_answer}\\n\"\n            \"\\n\"\n            \"## Issues to Address from the Review\\n\"\n            \"{review_points}\\n\"\n        )\n    }\n\n    # ---------- format helpers ----------\n    @staticmethod\n    def _format_contexts(ctxs: Optional[Sequence[str]]) -> str:\n        \"\"\"\n        Formats a sequence of contexts as numbered blocks. Accepts None, str, or Sequence[str].\n        \"\"\"\n        if ctxs is None:\n            ctxs = []\n        if not isinstance(ctxs, (list, tuple)):\n            ctxs = [str(ctxs)]\n        lines = [f\"Context{i+1}: {str(c)}\" for i, c in enumerate(ctxs)]\n        return \"\\n\".join(lines) if lines else \"(no context provided)\"\n\n    @staticmethod\n    def as_user(content: str) -> dict:\n        return {\"role\": \"user\", \"content\": content}\n\n    @staticmethod\n    def as_system(content: str) -> dict:\n        return {\"role\": \"system\", \"content\": content}\n\n    # ---------- prompt builders ----------\n    @classmethod\n    def build_solve(cls, question: str, contexts: Optional[Sequence[str]]) -> str:\n        return cls.PROMPT[\"solve\"].format(\n            question=question,\n            context=cls._format_contexts(contexts)\n        )\n\n    @classmethod\n    def build_review(cls, question: str, contexts: Optional[Sequence[str]], previous_answer: str) -> str:\n        return cls.PROMPT[\"review\"].format(\n            question=question,\n            context=cls._format_contexts(contexts),\n            previous_answer=previous_answer\n        )\n\n    @classmethod\n    def build_revise(\n        cls,\n        question: str,\n        contexts: Optional[Sequence[str]],\n        previous_answer: str,\n        review_points: Optional[str]\n    ) -> str:\n        if not review_points:\n            review_points = \"- Correct all issues identified in the review.\"\n        return cls.PROMPT[\"revise\"].format(\n            question=question,\n            context=cls._format_contexts(contexts),\n            previous_answer=previous_answer,\n            review_points=review_points\n        )\n\n    # ---------- convenient message-pack builders (mirrors your style) ----------\n    @classmethod\n    def msgs_solve(cls, question: str, contexts: Optional[Sequence[str]]) -> List[dict]:\n        return [\n            cls.as_system(\"You must use ONLY the provided contexts. Be concise and precise.\"),\n            cls.as_user(cls.build_solve(question, contexts))\n        ]\n\n    @classmethod\n    def msgs_review(cls, question: str, contexts: Optional[Sequence[str]], prev_answer: str) -> List[dict]:\n        return [\n            cls.as_system(\"Be a strict critic. Do NOT provide a new answer.\"),\n            cls.as_user(cls.build_review(question, contexts, prev_answer))\n        ]\n\n    @classmethod\n    def msgs_revise(\n        cls,\n        question: str,\n        contexts: Optional[Sequence[str]],\n        prev_answer: str,\n        review_points: Optional[str]\n    ) -> List[dict]:\n        return [\n            cls.as_system(\"Fix errors and finish with a single \\\\boxed{answer}. No extra text after the box.\"),\n            cls.as_user(cls.build_revise(question, contexts, prev_answer, review_points))\n        ]\n\ndef classify(x: str, n: int = 1200, dataset: str = \"metaqa\") -> pd.DataFrame:\n    BASE_PATHS = {\n        \"metaqa\": \"/kaggle/input/filtered-multiple-hops-metaqa\",\n        \"webqsp\": \"/kaggle/input/webqsp\"\n    }\n\n    # Validate dataset input\n    if dataset not in BASE_PATHS:\n        raise ValueError(f\"Invalid dataset '{dataset}'. Must be one of: {list(BASE_PATHS.keys())}\")\n\n    base = BASE_PATHS[dataset]\n    x = (x or \"\").strip().lower()\n\n    # Select file path based on dataset type\n    if dataset == \"metaqa\":\n        match x:\n            case \"one\":\n                path = f\"{base}/one_hop_supported.pickle\"\n            case \"three\" | _:\n                path = f\"{base}/three_hop_supported.pickle\"\n    else:  # dataset == \"another\"\n        match x:\n            case \"one\":\n                path = f\"{base}/webqsp_ctxstyle_1200_hop1_nl.pkl\"\n            case \"three\":\n                path = f\"{base}/webqsp_ctxstyle_1200_hop3_nl.pkl\"\n            case \"two\" | _:\n                raise ValueError(\"❌ 'two_hop_supported.pickle' does not exist in the 'current' dataset.\")\n\n    # Load and return dataframe\n    df = pd.read_pickle(path)\n\n    if dataset ==\"webqsp\":\n        df=df.rename(columns={\n            \"ground_truth\":\"Label\",\n            \"contexts\": \"ctx_topk\"\n        })\n    \n    return df.head(n)","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset=\"webqsp\"\ndf = classify(\"three\", n = 1200, dataset=dataset)\n\n# Step 1: SOLVE\ndf['sc_solve'] = df.apply(lambda row: SelfCorrectPromptBuilder.msgs_solve(\n    row['question'], row['ctx_topk']), axis=1)\n\nDoraemon.set_provider('llama3')\nlogger = Doraemon.get_logger(logfile='self_correct_on_rag.log')\ntasks = df.to_dict(orient='records')\nsolve_out = await Inference.process_batches(tasks, logger, 'sc_solve')\ndf['sc_solve_a'] = pd.Series(solve_out, dtype='object')\n\n# Step 2: REVIEW (critique only, reminds about \\boxed{answer})\ndf['sc_review'] = df.apply(lambda row: SelfCorrectPromptBuilder.msgs_review(\n    row['question'], row['ctx_topk'], KG_RAG_Tool.extract_boxed_answer(row['sc_solve_a'])), axis=1)\n\ntasks = df.to_dict(orient='records')\nreview_out = await Inference.process_batches(tasks, logger, 'sc_review')\ndf['sc_review_a'] = pd.Series(review_out, dtype='object')","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3: REVISE (final corrected answer in \\boxed{...})\ndf['sc_revise'] = df.apply(lambda row: SelfCorrectPromptBuilder.msgs_revise(\n    row['question'], row['ctx_topk'], KG_RAG_Tool.extract_boxed_answer(row['sc_solve_a']), KG_RAG_Tool.extract_boxed_answer(row['sc_review_a'])), axis=1)\n\ntasks = df.to_dict(orient='records')\nrevise_out = await Inference.process_batches(tasks, logger, 'sc_revise')\ndf['sc_revise_a'] = pd.Series(revise_out, dtype='object')\n\ndf['final_a'] = df['sc_revise_a'].apply(KG_RAG_Tool.extract_boxed_answer)\nprint(KG_RAG_Tool.eval_accuracy(df, pred='final_a', g_t='Label'))\n\ndf.to_pickle('self_correct.pkl')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}